{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28399f20",
   "metadata": {},
   "source": [
    "11/25 (Tue)\n",
    "\n",
    "---\n",
    "\n",
    "# Spliting Target Audio Segment from 1st Read-Aloud Recordings\n",
    "\n",
    "This notebook demonstrates how to split target audio segments from the first read-aloud recordings using Python's `pydub` library.\n",
    "The target segment is the following sentence (cf. Udofot, 2003):\n",
    "> \"Mosquito went away humiliated\"\n",
    "\n",
    "Note that the timestamps for the target segment were initially annotated by forced alignment and then manually corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228b25c",
   "metadata": {},
   "source": [
    "The following code cell imports the necessary libraries and sets up the file paths for the conversion process using Praat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f617378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryuki/Development/l2speech-ree-group-proj/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from textgrids import TextGrid, Tier\n",
    "\n",
    "from l2speech_ree_group_proj import PROCESSED_DATA_DIR, EXTERNAL_DATA_DIR\n",
    "\n",
    "TARGET_SEGMENT_WORDS = [\"mosquito\", \"went\", \"away\", \"humiliated\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66e4ba",
   "metadata": {},
   "source": [
    "The following code cell explores audio files and their corresponding annotation files to identify the target segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e916a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_wav_path_list = []\n",
    "target_textgrid_path_list = []\n",
    "\n",
    "for wav_path in PROCESSED_DATA_DIR.glob(\"*.wav\"):\n",
    "    textgrid_path = EXTERNAL_DATA_DIR / f\"{wav_path.stem}_manual.TextGrid\"\n",
    "\n",
    "    if not textgrid_path.exists():\n",
    "        continue\n",
    "\n",
    "    target_wav_path_list.append(wav_path)\n",
    "    target_textgrid_path_list.append(textgrid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f916b4",
   "metadata": {},
   "source": [
    "The following code cell identifies the start and end times of the target segments from the annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afa695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_list = []\n",
    "\n",
    "for textgrid_path in target_textgrid_path_list:\n",
    "    textgrid = TextGrid(filename=str(textgrid_path))\n",
    "\n",
    "    tier = textgrid[\"words\"]\n",
    "\n",
    "    start_time = 0.0\n",
    "    end_time = 0.0\n",
    "    current_pointer = 0\n",
    "\n",
    "    for interval in tier:\n",
    "        if interval.text == \"\":\n",
    "            continue\n",
    "\n",
    "        if interval.text == TARGET_SEGMENT_WORDS[current_pointer]:\n",
    "            if current_pointer == 0:\n",
    "                start_time = interval.xmin\n",
    "            current_pointer += 1\n",
    "\n",
    "            if current_pointer == len(TARGET_SEGMENT_WORDS):\n",
    "                end_time = interval.xmax\n",
    "                break\n",
    "        else:\n",
    "            current_pointer = 0\n",
    "\n",
    "    timestamp_list.append((start_time, end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47c6cb",
   "metadata": {},
   "source": [
    "The following code cell splits the target audio segments from the original recordings based on the identified timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(timestamp_list) != len(target_wav_path_list):\n",
    "    raise ValueError(\"Mismatch between number of timestamps and wav files.\")\n",
    "\n",
    "for wav_path, timestamp in zip(target_wav_path_list, timestamp_list):\n",
    "    if not wav_path.exists():\n",
    "        raise FileNotFoundError(f\"{wav_path} does not exist.\")\n",
    "\n",
    "    output_dir = PROCESSED_DATA_DIR / \"mosquito_away_segments\"\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "    start_ms = int(timestamp[0] * 1000)\n",
    "    end_ms = int(timestamp[1] * 1000)\n",
    "\n",
    "    segment = audio[start_ms:end_ms]\n",
    "\n",
    "    output_wav_path = output_dir / wav_path.name\n",
    "    segment.export(output_wav_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675b1de",
   "metadata": {},
   "source": [
    "The following code cell splits the target TextGrid files to correspond with the extracted audio segments.\n",
    "Also, I added tiers, \"syllables\" and \"stress\", to the split TextGrid files for further analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74a99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(timestamp_list) != len(target_textgrid_path_list):\n",
    "    raise ValueError(\"Mismatch between number of timestamps and TextGrid files.\")\n",
    "\n",
    "for textgrid_path, timestamp in zip(target_textgrid_path_list, timestamp_list):\n",
    "    if not textgrid_path.exists():\n",
    "        raise FileNotFoundError(f\"{textgrid_path} does not exist.\")\n",
    "\n",
    "    output_dir = PROCESSED_DATA_DIR / \"mosquito_away_segments\"\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    textgrid = TextGrid(filename=str(textgrid_path))\n",
    "\n",
    "    tier = textgrid[\"words\"]\n",
    "\n",
    "    segmented_intervals = []\n",
    "    for interval in tier:\n",
    "        if interval.xmax < timestamp[0]:\n",
    "            continue\n",
    "        if interval.xmin > timestamp[1]:\n",
    "            break\n",
    "\n",
    "        new_xmin = max(interval.xmin, timestamp[0]) - timestamp[0]\n",
    "        new_xmax = min(interval.xmax, timestamp[1]) - timestamp[0]\n",
    "\n",
    "        new_interval = deepcopy(interval)\n",
    "        new_interval.xmin = new_xmin\n",
    "        new_interval.xmax = new_xmax\n",
    "\n",
    "        if new_interval.xmin == new_interval.xmax:\n",
    "            continue\n",
    "\n",
    "        segmented_intervals.append(new_interval)\n",
    "\n",
    "    new_tier = Tier(data=segmented_intervals, xmin=0.0, xmax=timestamp[1] - timestamp[0])\n",
    "\n",
    "    new_textgrid = TextGrid()\n",
    "    new_textgrid.xmin = 0.0\n",
    "    new_textgrid.xmax = timestamp[1] - timestamp[0]\n",
    "\n",
    "    syllable_tier = Tier(data=[], xmin=0.0, xmax=timestamp[1] - timestamp[0])\n",
    "    new_textgrid[\"syllables\"] = syllable_tier\n",
    "\n",
    "    stress_tier = Tier(data=[], xmin=0.0, xmax=timestamp[1] - timestamp[0])\n",
    "    new_textgrid[\"stress\"] = stress_tier\n",
    "\n",
    "    new_textgrid[\"words\"] = new_tier\n",
    "\n",
    "    output_textgrid_path = output_dir / textgrid_path.name\n",
    "    new_textgrid.write(str(output_textgrid_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c35f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2speech-ree-group-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
